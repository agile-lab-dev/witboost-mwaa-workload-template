### Prerequisites

A Data Product should already exist in order to attach the new components to it.
The components **[Airbyte Workload](https://github.com/agile-lab-dev/witboost-airbyte-workload-template)**, **[Snowflake Output Port](https://github.com/agile-lab-dev/witboost-snowflake-output-port-template)**, and the **[Snowflake SQL Workload](https://github.com/agile-lab-dev/witboost-snowflake-sql-workload-template)** (or) **[DBT Workload](https://github.com/agile-lab-dev/witboost-dbt-workload-template)** should exist in the Data Product.


### Component Basic Information

This section includes the basic information that any Component of Witboost must have:

- Name: Displayed name for the new Data Product Component.
- Fully Qualified Name: Workload fully qualified name, this is optional as will be generated by the system if not given by you.
- Description: A short description to help others understand what this Workload is for.
- Domain: The Domain of the Data Product this Workload belongs to. Be sure to choose it correctly as it is a fundamental part of the Workload and cannot be changed afterwards.
- Data Product: The Data Product this Workload belongs to, be sure to choose the right one.
- Identifier: Unique ID for this new entity inside the domain. Don't worry to fill this field, it will be automatically filled for you. It will be automatically generated based on the information previously provided.
- Development Group: Development group of this Data Product. Don't worry to fill this field, it will be automatically filled for you.
- Depends On: If you want your Workload to depend on other components of the Data Product, you can choose this option (Optional).


> In the case of the MWAA operator, you should add here the **Snowflake Output Port, the Airbyte Component, and the SQL Workload Component (if present)** from the Data Product in order for the orchestrator to execute only when these components are in place.


*Example:*

| Field name              | Example value                                                                                                                                                                                                            |
|:------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **Name**                | Airflow Orchestration                                                                                                                                                                                                    |
| **Description**         | Orchestrator                                                                                                                                                                                                             |
| **Domain**              | domain:healthcare                                                                                                                                                                                                        |
| **Data Product**        | system:healthcare.vaccinations.0                                                                                                                                                                                         |
| **_Identifier_**        | _healthcare.vaccinations.0.airflow-orchestration_                                                                                                                                                                        |
| **_Development Group_** | _group:datameshplatform_                                                                                                                                                                                                 |
| **Depends On**          | urn:dmb:cmp:healthcare:vaccinations:0:airbyte-vaccinations-ingestion, urn:dmb:cmp:healthcare:vaccinations:0:snowflake-vaccinations-sql-workload, urn:dmb:cmp:healthcare:vaccinations:0:snowflake-vaccination-output-port |


### Airflow Infrastructure Details

In this section, you are expected to fill in details pertaining to Airflow.

- Cron expression defining schedule: Time (UTC) at which the Job will trigger (Required).
- Dag File Name: Name of the Dag File (Required).

*Example:*

| Field name          | Example value            |
|:--------------------|:-------------------------|
| **Cron expression** | 5 5 \* \* \*             |
| **Dag name**        | airbyte_snowflake_dag.py |

#### Cron Expressions

For those who are not aware of what cron expressions are, below is a brief summary:

- `Cron` is a basic utility available on Unix-based systems.

- It enables users to schedule tasks to run periodically at a specified date/time. It's a great tool for automating lots of process runs, which otherwise would require human intervention.

- Cron runs as a daemon process. This means it only needs to be started once, and it will keep running in the background.

- A `Cron Expression` looks like the below one:
    - `<minute> <hour> <day-of-month> <month> <day-of-week>`

- Some of the special characters that can be utilized within the Cron Expression are:
    - `* (all)` - It specifies that event should happen for every time unit. For example, "*" in the minute field means "for every minute".
    - `? (any)` - It is utilized in `<day-of-month>` and `<day-of-week>` fields of the cron expression to denote an arbitrary value and thus neglect the field value.
    - `- (range)` - It determines the range of values. For example, "10-11" in the `<hour>` field means "10th and 11th hours".
    - `, (values)` - It specifies multiple values. For example, "MON, WED, FRI" in `<day-of-week>` field means on the days “Monday, Wednesday and Friday”.
    - `/ (increments)` - It specifies the incremental values. For example, A “5/15” in the `<minute>` field means at “5, 20, 35 and 50 minutes of an hour.”

If you want to create your own cron expression and insert the same instead of the default one, you can refer to [Cron Expression Generator](https://crontab.guru/) to create a cron expression.

To know more in-depth details about DAG Scheduling, please [refer to this link](https://airflow.apache.org/docs/apache-airflow/stable/authoring-and-scheduling/index.html) which gives details about scheduling.

At this point, the component should be correctly initialised and the related repository created. By default, the MWAA python DAG file does not contain any operators, since we don't know in advance what operators the user will need to perform the needed interaction with the other components. As the MWAA component is based on a generic template, you are free to customize the DAG file in order to perform all the operations needed (e.g. to trigger multiple DBT workloads, multiple Airbyte connection, etc.)